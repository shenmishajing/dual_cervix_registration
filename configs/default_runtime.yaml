trainer:
    logger:
        class_path: utils.loggers.wandb.WandbNamedLogger
        init_args:
            name: dual_cervix_registration
            project: dual_cervix_registration
            offline: false
    callbacks:
        -   class_path: utils.progress.rich_progress.RichDefaultThemeProgressBar
            init_args:
                show_version: true
        -   class_path: pytorch_lightning.callbacks.RichModelSummary
            init_args:
                max_depth: 2
        -   class_path: utils.callbacks.set_sharing_strategy_callback.SetSharingStrategyCallback
            init_args:
                strategy: file_descriptor
        -   class_path: utils.callbacks.wandb_logger_watch_model_callback.WandbLoggerWatchModelCallback
            init_args:
                log: all
                log_freq: 50
                log_graph: true
        -   class_path: utils.callbacks.lr_monitor.LearningRateMonitor
            init_args:
                logging_interval: null
                log_momentum: false
                name_prefix: lr/
        -   class_path: utils.callbacks.model_checkpoint.ModelCheckpointWithSymlink
            init_args:
                monitor: val/loss
                filename: 'epoch:{epoch}-val_loss:{val/loss:.4g}'
                save_top_k: 3
                save_last: true
                mode: min
                auto_insert_metric_name: false
    # debug
    limit_train_batches: 1.0
    limit_val_batches: 1.0
    limit_test_batches: 1.0
    limit_predict_batches: 1.0
    fast_dev_run: false
    overfit_batches: 0.0
    # train
    max_epochs: null
    min_epochs: null
    max_steps: -1
    min_steps: null
    max_time: null
    # gradient clip
    gradient_clip_val: null
    gradient_clip_algorithm: null
    # path
    weights_save_path: work_dirs
    # gpus
    num_nodes: 1
    num_processes: 1
    gpus: -1
    strategy: null
    sync_batchnorm: false
    # speed up
    precision: 32
    auto_lr_find: false
    detect_anomaly: true
    auto_scale_batch_size: false
    accumulate_grad_batches: null
    profiler: null
    # val and log
    check_val_every_n_epoch: 1
    val_check_interval: 1.0
    flush_logs_every_n_steps: null
    log_every_n_steps: 50
    track_grad_norm: -1
# check point
ckpt_path: null
# seed
seed_everything: null
